---
title: "Take-home Exercise 3: Vast Challenge 2025 MC3"
author: "CHJ1"
date: "14 June 2025"
date-modified: "last-modified"
filters:
  - shinylive
format:
  html:
    resources:
      - shinylive-sw.js
editor: visual
execute:
  eval: true
  echo: true
  warning: false
  freeze: true
---

# I am working on this project with Teo Wee Siang Roy.

# I will be working on the Communication Patterns Analysis module of Take-home Exercise 3. This module includes daily communication volume, hourly communication volume, a heatmap of communication patterns based on date and hour, contents of the communcations, and a communication network graph.

# Storyboard of our group's Shiny application will also be outlined below.

# Load Packages

```{r}
pacman::p_load(tidyverse, jsonlite,
               tidygraph, ggraph,
               SmartEDA, igraph)
```

# Importing Data

```{r}
MC3 <- fromJSON("data/MC3_graph.json")
MC3_schema <- fromJSON("data/MC3_schema.json")
```

# Inspect Structure

```{r}
glimpse(MC3)
```

# Extracting the edges and nodes tables

```{r}
mc3_nodes <- as_tibble(MC3$nodes)
mc3_edges <- as_tibble(MC3$edges)
```

# Cleaning and wrangling nodes

```{r}
mc3_nodes_cleaned <- mc3_nodes %>%
  mutate(id = as.character(id)) %>%
  filter(!is.na(id)) %>%
  distinct(id, .keep_all = TRUE) %>%
  select(-thing_collected)
```

```{r}
mc3_edges_cleaned <- mc3_edges %>%
  rename(from_id = source, 
         to_id = target) %>%
  mutate(across(c(from_id, to_id), 
                as.character)) %>%
  filter(from_id %in% mc3_nodes_cleaned$id, 
         to_id %in% mc3_nodes_cleaned$id) %>%
  filter(!is.na(from_id), !is.na(to_id))
```

```{r}
node_index_lookup <- mc3_nodes_cleaned %>%
  mutate(.row_id = row_number()) %>%
  select(id, .row_id)
```

```{r}
mc3_edges_indexed <- mc3_edges_cleaned %>%
  left_join(node_index_lookup, 
            by = c("from_id" = "id")) %>%
  rename(from = .row_id) %>%
  left_join(node_index_lookup, 
            by = c("to_id" = "id")) %>%
  rename(to = .row_id) %>%
  select(from, to, is_inferred, type) %>%
  filter(!is.na(from) & !is.na(to))  
```

```{r}
used_node_indices <- sort(
  unique(c(mc3_edges_indexed$from, 
           mc3_edges_indexed$to)))

mc3_nodes_final <- mc3_nodes_cleaned %>%
  slice(used_node_indices) %>%
  mutate(new_index = row_number())
```

```{r}
old_to_new_index <- tibble(
  old_index = used_node_indices,
  new_index = seq_along(
    used_node_indices))
```

```{r}
mc3_edges_final <- mc3_edges_indexed %>%
  left_join(old_to_new_index, 
            by = c("from" = "old_index")) %>%
  rename(from_new = new_index) %>%
  left_join(old_to_new_index, 
            by = c("to" = "old_index")) %>%
  rename(to_new = new_index) %>%
  select(from = from_new, to = to_new, 
         is_inferred, type)
```

# Building the tidygraph object

```{r}
mc3_graph <- tbl_graph(
  nodes = mc3_nodes_final,
  edges = mc3_edges_final,
  directed = TRUE
)
```

```{r}
str(mc3_graph)
```

# Visualising the knowledge graph

```{r}
set.seed(1234)
```

```{r}
ggraph(mc3_graph, 
       layout = "fr") +
  geom_edge_link(alpha = 0.3, 
                 colour = "gray") +
  geom_node_point(aes(color = `type`), 
                  size = 4) +
  geom_node_text(aes(label = type), 
                 repel = TRUE, 
                 size = 2.5) +
  theme_void()
```

# Extract and Prepare Communication Events

```{r}
library(lubridate)

# Filter communication events
comm_nodes <- mc3_nodes_final %>%
  filter(type == "Event", sub_type == "Communication") %>%
  mutate(timestamp = ymd_hms(timestamp))

# Remove missing timestamps
comm_nodes <- comm_nodes %>% filter(!is.na(timestamp))
```

# Aggregate Communications by Day and Hour

```{r}
comm_nodes <- comm_nodes %>%
  mutate(date = as.Date(timestamp),
         hour = hour(timestamp))
```

```{r}
daily_counts <- comm_nodes %>%
  group_by(date) %>%
  summarise(comm_count = n())

hourly_counts <- comm_nodes %>%
  group_by(date, hour) %>%
  summarise(comm_count = n())
```

# Module for Shiny Application

```{r}
library(shiny)
library(ggplot2)
library(dplyr)
library(plotly)
library(lubridate)
library(DT)
library(visNetwork)  

ui <- fluidPage(
  titlePanel("Communication Patterns Analysis"),
  sidebarLayout(
    sidebarPanel(
      dateRangeInput("date_filter", "Date Range:",
                     start = min(comm_nodes$date),
                     end = max(comm_nodes$date)),
      sliderInput("hour_filter", "Hour Range:",
                  min = 0, max = 23,
                  value = c(0, 23)),
      width = 3
    ),
    mainPanel(
      tabsetPanel(
        tabPanel("Daily", plotOutput("daily_plot")),
        tabPanel("Hourly", plotOutput("hourly_plot")),
        tabPanel("Heatmap", plotlyOutput("heatmap")),
        tabPanel("Messages", DTOutput("messages_table")),
        tabPanel("Network Graph", visNetworkOutput("network_plot", height = "800px"))  # Interactive!
      ),
      width = 9
    )
  )
)

server <- function(input, output) {
  # Filtered communication events by date and hour
  filtered_data <- reactive({
    comm_nodes %>%
      filter(date >= input$date_filter[1],
             date <= input$date_filter[2],
             hour >= input$hour_filter[1],
             hour <= input$hour_filter[2])
  })

  # Daily Plot
  output$daily_plot <- renderPlot({
    daily_counts <- filtered_data() %>%
      group_by(date) %>%
      summarise(comm_count = n())
    ggplot(daily_counts, aes(x = date, y = comm_count)) +
      geom_col(fill = "steelblue") +
      geom_text(aes(label = comm_count), vjust = -0.5, size = 3) +
      geom_smooth(method = "lm", se = FALSE, color = "red", linetype = "dashed") +
      scale_x_date(date_labels = "%Y-%m-%d", expand = expansion(mult = c(0.01, 0.1))) +
      labs(title = "Daily Communication Volume",
           x = "Date", y = "Count") +
      theme_minimal()
  })

  # Hourly Plot
  output$hourly_plot <- renderPlot({
    hourly_totals <- filtered_data() %>%
      group_by(hour) %>%
      summarise(comm_count = n())
    ggplot(hourly_totals, aes(x = hour, y = comm_count)) +
      geom_col(fill = "steelblue") +
      geom_text(aes(label = comm_count), vjust = -0.5, size = 3) +
      geom_smooth(method = "lm", se = FALSE, color = "red", linetype = "dashed") +
      labs(title = "Hourly Communication Volume",
           x = "Hour", y = "Count") +
      theme_minimal()
  })

  # Heatmap
  output$heatmap <- renderPlotly({
    hourly_counts <- filtered_data() %>%
      group_by(date, hour) %>%
      summarise(comm_count = n(), .groups = "drop")
    p <- ggplot(hourly_counts, aes(
      x = hour, y = date, fill = comm_count,
      text = paste("Date:", date,
                   "<br>Hour:", hour,
                   "<br>Communications:", comm_count))) +
      geom_tile(color = "white") +
      scale_fill_gradient(low = "white", high = "firebrick") +
      scale_y_date(date_labels = "%Y-%m-%d") +
      labs(title = "Hourly Communication Patterns",
           x = "Hour", y = "Date") +
      theme_minimal()
    ggplotly(p, tooltip = "text")
  })

  # Messages Table
  output$messages_table <- renderDT({
    filtered_data() %>%
      arrange(desc(timestamp)) %>%
      mutate(Time = format(timestamp, "%Y-%m-%d %H:%M:%S")) %>%
      select(Time, Content = content)
  }, options = list(
      pageLength = 10,
      autoWidth = TRUE,
      scrollX = TRUE,
      columnDefs = list(
        list(width = '20%', targets = 0),
        list(width = '80%', targets = 1)
      )
    ),
    rownames = FALSE
  )

  # Interactive Network Graph
  output$network_plot <- renderVisNetwork({
    req(filtered_data())
    # Get nodes in filtered timeframe
    peak_comm_ids <- filtered_data() %>% pull(new_index)
    # Get edges involving these nodes
    peak_edges <- mc3_edges_final %>%
      filter(from %in% peak_comm_ids | to %in% peak_comm_ids)
    # Get unique node indices from edges
    used_indices <- unique(c(peak_edges$from, peak_edges$to))
    # Create filtered node table
    peak_nodes_sub <- mc3_nodes_final %>%
      filter(new_index %in% used_indices) %>%
      mutate(sub_index = row_number())
    # Update edge indices
    peak_edges_sub <- peak_edges %>%
      left_join(select(peak_nodes_sub, old_index = new_index, from_sub = sub_index), 
                by = c("from" = "old_index")) %>%
      left_join(select(peak_nodes_sub, old_index = new_index, to_sub = sub_index), 
                by = c("to" = "old_index")) %>%
      select(from = from_sub, to = to_sub, is_inferred, type) %>%
      filter(!is.na(from) & !is.na(to)) %>%
      mutate(id = row_number(),
             arrows = ifelse(is_inferred, "to;from", "to"),
             dashes = is_inferred,
             title = paste("Edge type:", type))
    # Prepare nodes for visNetwork
    nodes_vis <- peak_nodes_sub %>%
      mutate(
        id = sub_index,
        label = paste0(label, "\n(", type, ")"),
        group = type,
        title = paste0(
          "Name: ", label, 
          "\nType: ", type,
          if ("sub_type" %in% names(.)) paste0("\nSubtype: ", sub_type) else "",
          "\nConnections: ", purrr::map_dbl(sub_index, ~sum(peak_edges_sub$from == .x | peak_edges_sub$to == .x))
        )
      )
    # visNetwork plot
    visNetwork(nodes_vis, peak_edges_sub, height = "800px", width = "100%") %>%
      visOptions(
        highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),
        nodesIdSelection = TRUE,
        selectedBy = list(variable = "group", multiple = TRUE)
      ) %>%
      visPhysics(stabilization = TRUE) %>%
      visInteraction(navigationButtons = TRUE) %>%
      visLegend()
  })
}

shinyApp(ui, server)
```

# Storyboard of Shiny Application

The aim of our Shiny application is to identify suspicious communication patterns.

The combination of the daily communication volume bar chart, hourly communication volume bar chart, and the hourly heat map is one way to detect temporal anomalies and shifts in communication behaviour.

<img src="image/Screenshot2025-06-15at3.24.51PM.png" alt="test" style="max-width: 100%;"/>

Daily Communication Volume Bar Chart

This chart displays the number of communications per day, overlaid with a red dashed trend line. It allows analysts to quickly spot days with unusually high or low activity, as well as to observe overall trends such as gradual increases or decreases in daily volume. A sudden spike or drop may indicate an event or coordinated action that warrants further attention.

<img src="image/Screenshot2025-06-15at3.30.17PM.png" alt="test" style="max-width: 100%;"/>

Hourly Communication Volume Bar Chart

By aggregating the number of communications by hour across the dataset and plotting a trend line, this chart reveals the typical daily rhythm of communications. Significant deviations from the expected hourly pattern, such as an unusual surge in late-night or early-morning activity, can be a red flag for out-of-pattern behaviour.

<img src="image/Screenshot2025-06-15at3.31.54PM.png" alt="test" style="max-width: 100%;"/>

Hourly Communication Heat Map

The heat map visualises the intensity of communications for each hour of each day, making it easy to spot recurring peaks or abrupt changes. Consistent high activity during certain hours may be normal, but a shift in these patterns, such as a new peak at an odd hour or an isolated day with unusual activity, can signal suspicious coordination or attempts to evade detection.

Together, these temporal visualisations enable analysts to:

1.  Detect when communication patterns deviate from the established norm.
2.  Pinpoint specific dates and hours where suspicious activity is concentrated.
3.  Observe whether suspicious patterns are isolated incidents or part of a broader trend.

<img src="image/Screenshot2025-06-15at3.34.37PM.png" alt="test" style="max-width: 100%;"/>

Communication Network Graph

The communication network graph provides a structural snapshot of the network at any selected date and time. By filtering the network to a specific window (identified as suspicious via the temporal charts), analysts can:

1.  Visualise which entities are most active or central during periods of interest.

2.  Identify clusters, bridges, or unusually dense connections that may indicate coordinated groups or key facilitators.

3.  Assess the scale and reach of the network at critical moments, helping to distinguish between routine communication and orchestrated events.

This graph is essential for understanding not just when, but who is involved in suspicious activity, and how information or influence flows between individuals and organisations.

A slicer has been incorporated on the left side of the dashboard, allowing users to filter all visualisations by date and time. This interactive control enables analysts to dynamically adjust the temporal scope of the data displayed, making it easier to focus on specific periods of interest and observe how communication patterns and network structures change over time

<img src="image/Screenshot2025-06-15at3.33.36PM.png" alt="test" style="max-width: 100%;"/>

Deep Dive: The Messages Tab

Once a suspicious period is identified through the above visualisations, the messages tab allows for targeted review of the actual message content exchanged during that window. This enables:

1.  Direct examination of the nature and context of communications, confirming whether the content aligns with legitimate business or hints at illicit coordination.

2.  Identification of code words, unusual instructions, or references to sensitive operations.

3.  Verification of relationships and roles among key entities, as messages often reveal hierarchy, influence, and intent.

By correlating message content with network structure and temporal anomalies, analysts can move from pattern detection to concrete evidence gathering, supporting investigations into illegal or unethical activities.

Cluster

The visualisation reveals the complex web of relationships in the Oceanus maritime environment around Nemo Reef. This network map serves as a digital detective board, showing how 33 key entities, both people and vessels, communicate and interact in this sensitive marine area.

The Communication Patterns:

<img src="image/Screenshot2025-06-15at4.09.10PM.png" alt="test" style="max-width: 100%;"/>

Central Hub Activity: Kelly and Sam emerge as information brokers, maintaining connections across multiple groups, potentially serving as intermediaries between legitimate and suspicious operations.

Isolated Operations: Some entities like Northern Light and Mariner's Dream operate with limited connections, suggesting either independent operations or intentional isolation.

Bridge Connections: Certain individuals like Nadia Conti and Liam Thorne serve as critical bridges between official channels and operational networks.

Cluster Analysis

The dashboard presents a comparative analysis of different clustering algorithms applied to the Oceanus maritime network, aiming to uncover meaningful communities among people and vessels involved around Nemo Reef.

<img src="image/Screenshot2025-06-15at4.12.50PM.png" alt="test" style="max-width: 100%;"/>

The Entity Communication Network reveals that Nemo Reef operations exist within a complex ecosystem where environmental protection, legitimate tourism, and potentially suspicious activities intersect. The visualisation provides maritime authorities with a strategic overview to prioritise investigations, enhance monitoring of key relationships, and protect both marine conservation efforts and legitimate maritime commerce while identifying threats to the reef's ecological integrity.

The story this network tells: While legitimate conservation and tourism operations maintain their protective roles around Nemo Reef, a concerning undercurrent of potentially coordinated suspicious activities requires immediate investigative attention to preserve both maritime security and environmental protection in these critical waters.
